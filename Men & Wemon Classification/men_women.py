# -*- coding: utf-8 -*-
"""men-women.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LklKCwm3bfZNMfEYh0zlEDzEagJKmA71

# Men-Women Detection
"""

import os
import shutil , pathlib
from tensorflow.keras.utils import image_dataset_from_directory
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

"""##1-Dataset Preparation

###1-1 Download Dataset from Kaggle
"""

from google.colab import files
_ = files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d saadpd/menwomen-classification

!unzip -qq menwomen-classification.zip

"""###1-2 Dataset Evaluation"""

num_men_train = len(os.listdir('/content/traindata/traindata/men'))
num_women_train = len(os.listdir('/content/traindata/traindata/women'))

num_men_test = len(os.listdir('/content/testdata/testdata/men'))
num_women_test = len(os.listdir('/content/testdata/testdata/women'))

print(f'Train men: {num_men_train} | women: {num_women_train}')
print(f'Test men: {num_men_test} | women: {num_women_test}')

"""###1-3 Prepare Data Direction"""

new_base_dir = pathlib.Path('men_vs_women_small')

def make_subset(base_dir , subset_name , start_index , end_index):
  for category in ('men' , 'women'):
    dir = new_base_dir / subset_name / category
    if not os.path.exists(dir):
      os.makedirs(dir)
    files = os.listdir(os.path.join(base_dir , category))
    fnames = [files[i] for i in range(start_index , end_index)]
    for fname in fnames:
      shutil.copyfile(src= os.path.join(base_dir , category, fname) ,
                      dst= os.path.join(dir , fname))

make_subset('traindata/traindata' , "validation" , start_index=0 , end_index=200)
make_subset('traindata/traindata' , "train" , start_index=200 , end_index=999)
make_subset('testdata/testdata' , "test" , start_index=0 , end_index=400)

"""###1-4 Load Dataset"""

#Train Dataset
print('Train Loader')
train_dataset = image_dataset_from_directory(
    'men_vs_women_small/train',
    image_size=(180,180),
    batch_size=32,
    label_mode='binary'
)

#Validation Dataset
print('Validation Loader')
validation_dataset = image_dataset_from_directory(
    'men_vs_women_small/validation',
    image_size=(180,180),
    batch_size=32,
    label_mode='binary'
)

#Test Dataset
print('Test Loader')
test_dataset = image_dataset_from_directory(
    'men_vs_women_small/test',
    image_size=(180,180),
    batch_size=32,
    label_mode='binary'
)

for data_batch , label_batch in train_dataset:
  print('data batch shape:' , data_batch.shape)
  print('labels batch shape:' , label_batch.shape)

  #show 5 random examples of the loaded batch
  fig , axes = plt.subplots(1, 5, figsize=(10,3))
  for i, ax in enumerate(axes):
    ax.imshow(data_batch[i].numpy().astype('uint8'))
    ax.set_axis_off()
    ax.set_title('Men' if label_batch[i].numpy()==0 else 'Women')
  break

plt.show()

"""##2- Model Design"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip('horizontal'),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2)
    ]
)

input = keras.Input(shape = (180, 180, 3))
x = data_augmentation(input)
x = layers.Rescaling(1./255)(x)
x = layers.Conv2D(filters=32 , kernel_size=3 , activation='relu')(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64 , kernel_size=3 , activation='relu')(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128 , kernel_size=3 , activation='relu')(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256 , kernel_size=3 , activation='relu')(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256 , kernel_size=3 , activation='relu')(x)
x = layers.Flatten()(x)
outputs = layers.Dense(units=1 , activation='sigmoid')(x)

model = keras.Model(inputs=input , outputs=outputs)

model.summary()

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath='men_vs_women.keras',
        save_best_only=True,
        monitor='val_loss'
    )
]

history = model.fit(
    train_dataset,
    epochs=30,
    validation_data=validation_dataset,
    callbacks=callbacks
)

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(accuracy) + 1)

plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

test_model = keras.models.load_model('men_vs_women.keras')
test_loss , test_acc = test_model.evaluate(test_dataset)
print(f'Test accuracy: {test_acc:.3f}')
