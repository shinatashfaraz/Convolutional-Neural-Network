# -*- coding: utf-8 -*-
"""men-women-TL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/122jjwAVGsIeo-0iUb7jPc21yc-CFbr0T

# Men-Women Detection
by Transfer Learning
"""

import os
import shutil , pathlib
from tensorflow.keras.utils import image_dataset_from_directory
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import numpy as np
import pandas as pd

"""##1-Dataset Preparation

###1-1 Download Dataset from Kaggle
"""

from google.colab import files
_ = files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d saadpd/menwomen-classification

!unzip -qq menwomen-classification.zip

"""###1-2 Dataset Evaluation"""

num_men_train = len(os.listdir('/content/traindata/traindata/men'))
num_women_train = len(os.listdir('/content/traindata/traindata/women'))

num_men_test = len(os.listdir('/content/testdata/testdata/men'))
num_women_test = len(os.listdir('/content/testdata/testdata/women'))

print(f'Train men: {num_men_train} | women: {num_women_train}')
print(f'Test men: {num_men_test} | women: {num_women_test}')

"""###1-3 Prepare Data Direction"""

new_base_dir = pathlib.Path('men_vs_women_small')

def make_subset(base_dir , subset_name , start_index , end_index):
  for category in ('men' , 'women'):
    dir = new_base_dir / subset_name / category
    if not os.path.exists(dir):
      os.makedirs(dir)
    files = os.listdir(os.path.join(base_dir , category))
    fnames = [files[i] for i in range(start_index , end_index)]
    for fname in fnames:
      shutil.copyfile(src= os.path.join(base_dir , category, fname) ,
                      dst= os.path.join(dir , fname))

make_subset('traindata/traindata' , "validation" , start_index=0 , end_index=200)
make_subset('traindata/traindata' , "train" , start_index=200 , end_index=999)
make_subset('testdata/testdata' , "test" , start_index=0 , end_index=400)

"""###1-4 Load Dataset"""

#Train Dataset
print('Train Loader')
train_dataset = image_dataset_from_directory(
    'men_vs_women_small/train',
    image_size=(180,180),
    batch_size=32,
    label_mode='binary'
)

#Validation Dataset
print('Validation Loader')
validation_dataset = image_dataset_from_directory(
    'men_vs_women_small/validation',
    image_size=(180,180),
    batch_size=32,
    label_mode='binary'
)

#Test Dataset
print('Test Loader')
test_dataset = image_dataset_from_directory(
    'men_vs_women_small/test',
    image_size=(180,180),
    batch_size=32,
    label_mode='binary'
)

for data_batch , label_batch in train_dataset:
  print('data batch shape:' , data_batch.shape)
  print('labels batch shape:' , label_batch.shape)

  #show 5 random examples of the loaded batch
  fig , axes = plt.subplots(1, 5, figsize=(10,3))
  for i, ax in enumerate(axes):
    ax.imshow(data_batch[i].numpy().astype('uint8'))
    ax.set_axis_off()
    ax.set_title('Men' if label_batch[i].numpy()==0 else 'Women')
  break

plt.show()

"""##2- Model Design"""

conv_base = keras.applications.vgg16.VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=(180,180,3)
)

def get_features_and_labels(dataset):
  all_features = []
  all_labels = []
  for images , labels in dataset:
    preprocessed_images = keras.applications.vgg16.preprocess_input(images)
    features = conv_base.predict(preprocessed_images, verbose= 0)
    all_features.append(features)
    all_labels.append(labels)
  return np.concatenate(all_features) , np.concatenate(all_labels)


train_features , train_labels = get_features_and_labels(train_dataset)
val_features , val_labels = get_features_and_labels(validation_dataset)
test_features , test_labels = get_features_and_labels(test_dataset)

train_features.shape

inputs = keras.Input(shape=(5 , 5 , 512))
x = layers.GlobalAveragePooling2D()(inputs)
x = layers.Dense(256)(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1 , activation='sigmoid')(x)
model = keras.Model(inputs , outputs)

model.summary()

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath='men_vs_women.keras',
        save_best_only=True,
        monitor='val_loss'
    )
]

history = model.fit(
    train_features , train_labels,
    epochs=30,
    validation_data=val_features , val_labels,
    callbacks=callbacks
)

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(accuracy) + 1)

plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

test_model = keras.models.load_model('men_vs_women.keras')
test_loss , test_acc = test_model.evaluate(test_features , test_labels)
print(f'Test accuracy: {test_acc:.3f}')